{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e12e8ed1",
   "metadata": {},
   "source": [
    "## Submission instruction \n",
    "\n",
    "1. For part 1, the notebook will generate python files in submission. The submission folder will need to be\n",
    "uploaded to the course website.\n",
    "2. While solving the assignment, do **NOT change class and method names**, autograder tests will fail\n",
    "otherwise. However, you can add utility functions into base class if needed.\n",
    "3. You'll also have to upload a **PDF version** of the notebook (which would be primarily used to grade your\n",
    "report section of the notebook).\n",
    "4. Deadline: **2022.12.16 23:00**\n",
    "\n",
    "Put the `submission` folder, 1 pdf exported from this notebook into one folder with name **student id_student name** , zip the folder and upload the course website (the teaching cube)."
   ]
  },
  {
   "attachments": {
    "phoneme_class.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "fa8df2e0",
   "metadata": {},
   "source": [
    "## Part1. Phoneme classification (70 points)\n",
    "\n",
    "### I. Overview\n",
    "\n",
    "This assignment includes two parts: **Phoneme classification (70 points)** and **Connectionist Temporal Classification (CTC) loss (30 points + 15 points for bonus)**. In the part 1, you are asked to classify audio segments into 7 phoneme classes (VS, NF, SF, WF, ST, CL and q for glotal ).\n",
    "\n",
    "In this part, you are asked to classify audio segments into 7 phoneme classes (VS, NF, SF, WF, ST, CL and q for glotal ). The meaning of those classes (except q) is given in the following table.\n",
    "\n",
    "\n",
    "![phoneme_class.png](attachment:phoneme_class.png)\n",
    "\n",
    "This assignment contains three tasks:\n",
    "\n",
    "    - Task 1: Data Preparation and Feature extraction (20 points)\n",
    "    - Task 2: A simple frame-based classification (35 points)\n",
    "    - Task 3: Written report (15 points)\n",
    "\n",
    "For Task 1, you are asked to use librosa to extract MFCC features from wavfiles. \n",
    "\n",
    "For Task 2, you are given a training dataset and a validation set in the folder audio/part-1. Your method will be evaluated on a hidden test set. Students who can achive results better than our  **simple baseline(Frame-based Accuracy 0.49ï¼ŒSegment-based Accuracy 0.43 )** can get maximum score of task 1.\n",
    "\n",
    "For Task 3, you are asked to report your experimental results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de657a9",
   "metadata": {},
   "source": [
    "### II. Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c65f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6adee8",
   "metadata": {},
   "source": [
    "`submission` contains all the files that you will submit; output contains the output files of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff5c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try: \n",
    "    os.mkdir('submission')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "try:\n",
    "   open('submission/__init__.py', 'x')\n",
    "except FileExistsError:\n",
    "   pass\n",
    "try: \n",
    "    os.mkdir('output')\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c983f8e5",
   "metadata": {},
   "source": [
    "### III. Data Preprocessing and Feature Extraction (20 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58cc9b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting submission/features.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile submission/features.py \n",
    "import glob\n",
    "import pickle\n",
    "import librosa\n",
    "import scipy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def wavfile_to_mfccs(wavfile):\n",
    "    \"\"\"\n",
    "    Returns a matrix of shape (nframes, 39), since there are 39 MFCCs (deltas\n",
    "    included for each 20ms frame in the wavfile).\n",
    "    \"\"\"\n",
    "    x, sampling_rate = librosa.load(wavfile)\n",
    "\n",
    "    window_duration_ms = 20\n",
    "    n_fft = int((window_duration_ms / 1000.) * sampling_rate)\n",
    "\n",
    "    hop_duration_ms = 10\n",
    "    hop_length = int((hop_duration_ms / 1000.) * sampling_rate)\n",
    "\n",
    "    mfcc_count = 13\n",
    "\n",
    "    #### BEGIN YOUR CODE  (5 points)\n",
    "    # Call librosa.feature.mfcc to get mfcc features for each frame of 20ms\n",
    "    # Call librosa.feature.delta on the mfccs to get mfcc_delta\n",
    "    # Call librosa.feature.delta with order 2 on the mfccs to get mfcc_delta2\n",
    "    # Stack all of them (mfcc, mfcc_delta, mfcc_delta2) together \n",
    "    # to get the matrix mfccs_and_deltas of size (#frames, 39)\n",
    "    mfcc = librosa.feature.mfcc(y=x, sr=sampling_rate, n_mfcc=mfcc_count, n_fft=n_fft, hop_length=hop_length)\n",
    "    mfcc_delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "    mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    mfccs_and_deltas = np.vstack([mfcc,mfcc_delta1,mfcc_delta2])\n",
    "    mfccs_and_deltas = mfccs_and_deltas.transpose(1,0)\n",
    "    #### END YOUR CODE\n",
    "\n",
    "    return mfccs_and_deltas, hop_length, n_fft\n",
    "\n",
    "class ShortTimeAnalysis:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def perform(self, wavfile):\n",
    "        pass\n",
    "    \n",
    "class MFCCAnalysis(ShortTimeAnalysis):\n",
    "    def perform(self, wavfile):\n",
    "        return wavfile_to_mfccs(wavfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46220270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c182ef50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\softwares\\anaconda3\\envs\\introRL\\python.exe\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26181b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6f1bf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(394, 39)\n"
     ]
    }
   ],
   "source": [
    "# Testing your method\n",
    "wavfile = \"audio/part-1/train/SA1.WAV\"\n",
    "\n",
    "X, hop_lengt, window_len = wavfile_to_mfccs(wavfile)\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98f81df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting submission/dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile submission/dataset.py \n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "import librosa\n",
    "import scipy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "import ipdb\n",
    "\n",
    "unique_classes = ['CL', 'SF', 'VS', 'WF', 'ST', 'NF', \"q\"]\n",
    "\n",
    "def read_data_folder(data_path):\n",
    "    \"\"\"\n",
    "    @return\n",
    "    wav_files: list of file paths to WAV files in the train or val folder.\n",
    "    labels_files: ist of file paths to PHNCLS files in the train or val folder.\n",
    "    \"\"\"\n",
    "    # get all the WAV and PHNCLS in the folder data_path\n",
    "    wav_files = sorted(glob.glob(data_path + \"/*.WAV\"))\n",
    "    labels_files = sorted(glob.glob(data_path + \"/*.PHNCLS\"))\n",
    "    return wav_files, labels_files\n",
    "\n",
    "# æå–segment labelså’Œrepresentations\n",
    "def extract_features(wavfile, label_file, first_seg_id=0, stanalysis=MFCCAnalysis()):\n",
    "    \"\"\"\n",
    "    Extract segment labels and representations.\n",
    "    \n",
    "    @arguments:\n",
    "    wavfile: path to wav file\n",
    "    label_file: path to PHNCLS file\n",
    "    first_seg_id: segment_id of the first segment of the current file.\n",
    "                  When you process a list of files, you may want segment id to increase globally.\n",
    "\n",
    "    @returns:\n",
    "    X: #frames, #features\n",
    "    y: #frames\n",
    "\n",
    "    frame2seg: mapping from frame id to segment id\n",
    "    y_seg: segment labels (segment-based groundtruth)\n",
    "    \"\"\"\n",
    "    #  mfccs_and_deltas, hop_length, n_fft    \n",
    "    X_st, hop_length, window_len = stanalysis.perform(wavfile)\n",
    "    # print(hop_length, window_len) # 220 441\n",
    "\n",
    "    seg_labels = {}\n",
    "    point_seg_ids = []\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            start_frame, end_frame, label = line.split(' ')\n",
    "            start_frame = int(start_frame)\n",
    "            end_frame = int(end_frame)\n",
    "            \n",
    "            label = label.strip()\n",
    "            segment_id = len(seg_labels) + first_seg_id\n",
    "            seg_labels[segment_id] = label\n",
    "            \n",
    "            phn_frames = end_frame - start_frame\n",
    "            # point_seg_ids stores segment ids for every sample point.\n",
    "            point_seg_ids.extend([segment_id]*phn_frames) \n",
    "            \n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    frame_seg_ids = []\n",
    "    curr_frame = curr_hop = 0\n",
    "    \n",
    "    while (curr_frame < (len(point_seg_ids) - window_len)):\n",
    "        ### BEGIN YOUR CODE (10 points)\n",
    "        \n",
    "        # extract the segment ids for the sample points within the frame \n",
    "        # from curr_frame to curr_frame + window_len\n",
    "        \n",
    "        # Since one frame may overlap with more than one segment, \n",
    "        # sample points within the frame may be assigned with multiple segment ids.\n",
    "        # We get the major segment id as the segment id corresponding to the current frame.\n",
    "        # ä¸»å…ƒç´ é—®é¢˜ï¼Œé‡‡ç”¨æ‘©å°”æŠ•ç¥¨ç®—æ³•ï¼Œæ—¶é—´å¤æ‚åº¦ä¸º O(n)\n",
    "        count = 0\n",
    "        for i in range(curr_frame, curr_frame + window_len):\n",
    "            if count:\n",
    "                if point_seg_ids[i] == major:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    count -= 1\n",
    "            else:\n",
    "                major = point_seg_ids[i]\n",
    "                count += 1\n",
    "        segment_id = major\n",
    "        ### END YOUR CODE\n",
    "\n",
    "        label = seg_labels[segment_id]\n",
    "        y.append(label)\n",
    "        X.append(X_st[curr_hop,:])\n",
    "        frame_seg_ids.append(segment_id)\n",
    "        \n",
    "        curr_hop += 1\n",
    "        curr_frame += hop_length\n",
    "    \n",
    "    return X, y, frame_seg_ids, seg_labels\n",
    "\n",
    "\n",
    "def prepare_data(wavfiles, label_files, stanalysis=MFCCAnalysis()):\n",
    "    X = []\n",
    "    y = []\n",
    "    segment_ids = []\n",
    "    seg2labels = {}\n",
    "    \n",
    "    file_seg_id = 0\n",
    "    for i in tqdm(range(len(wavfiles))):\n",
    "        wavfile = wavfiles[i]\n",
    "        label_file = label_files[i]\n",
    "        x_, y_, seg_ids_, seg_labels_ = extract_features(\n",
    "            wavfile, label_file, first_seg_id=file_seg_id, stanalysis=stanalysis)\n",
    "\n",
    "        file_seg_id += len(seg_labels_)\n",
    "        for k,v in seg_labels_.items():\n",
    "            seg2labels[k] = v\n",
    "\n",
    "        X.append(x_)\n",
    "        y.extend(y_)\n",
    "        segment_ids.extend(seg_ids_)\n",
    "        \n",
    "\n",
    "    X = np.concatenate(X)\n",
    "    return X, y, segment_ids, seg2labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fc765a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing \n",
    "wavfiles, label_files = read_data_folder(\"audio/part-1/train/\")\n",
    "X, y, segment_ids, seg2labels = prepare_data(wavfiles[0:1], label_files[0:1])\n",
    "print (X.shape) # 284 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b88152b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting submission/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile submission/preprocessing.py\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "# Training data Zero-centered \n",
    "def normalize_mean(X):\n",
    "    \"\"\"\n",
    "    Using scikit learn preprocessing to transform feature matrix\n",
    "    using StandardScaler with mean and standard deviation\n",
    "    \"\"\"\n",
    "    ### BEGIN YOUR CODE (3 points)\n",
    "    scaler = preprocessing.StandardScaler(with_std=False)\n",
    "    X = scaler.fit_transform(X)\n",
    "    ### END YOUR CODE\n",
    "    return X, scaler.mean_\n",
    "\n",
    "# Test data Zero-centered\n",
    "def apply_normalize_mean(X, scaler_mean):\n",
    "    \"\"\"\n",
    "    Apply normalizaton to a testing dataset that have been fit using training dataset.\n",
    "    \n",
    "    @arguments:\n",
    "    X: #frames, #features (in case we use mfcc, #features is 39)\n",
    "    scaler_mean: mean of fitted StandardScaler that you used in normalize_mean function.\n",
    "    \n",
    "    @returns:\n",
    "    X: normalized matrix\n",
    "    \"\"\" \n",
    "    ### BEGIN YOUR CODE (2 points)\n",
    "    X = X - scaler_mean\n",
    "    # X = X / scaler_std\n",
    "    ### END YOUR CODE\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15abf6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "X, scaler_mean = normalize_mean(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b662cca0",
   "metadata": {},
   "source": [
    "### IV. Phone Classifier (35 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a00032",
   "metadata": {},
   "source": [
    "In this part, we will perform isolated phone classification. We assume that phones are well segmented. This section includes two tasks: phone classifier with MFCC, and building your best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84c22988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting submission/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile submission/model.py\n",
    "\n",
    "import time,datetime\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sequential\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "\n",
    "def onehot_matrix(samples_vec, num_classes):\n",
    "    \"\"\"\n",
    "    >>> onehot_matrix(np.array([1, 0, 3]), 4)\n",
    "    [[ 0.  1.  0.  0.]\n",
    "     [ 1.  0.  0.  0.]\n",
    "     [ 0.  0.  0.  1.]]\n",
    "\n",
    "    >>> onehot_matrix(np.array([2, 2, 0]), 3)\n",
    "    [[ 0.  0.  1.]\n",
    "     [ 0.  0.  1.]\n",
    "     [ 1.  0.  0.]]\n",
    "\n",
    "    Ref: http://bit.ly/1VSKbuc\n",
    "    \"\"\"\n",
    "    num_samples = samples_vec.shape[0]\n",
    "\n",
    "    onehot = np.zeros(shape=(num_samples, num_classes))\n",
    "    onehot[range(0, num_samples), samples_vec] = 1\n",
    "\n",
    "    return onehot\n",
    "\n",
    "def segment_based_evaluation(y_pred, segment_ids, segment2label):\n",
    "    \"\"\"\n",
    "    @argments:\n",
    "    y_pred: predicted labels of frames\n",
    "    segment_ids: segment id of frames\n",
    "    segment2label: mapping from segment id to label\n",
    "    \"\"\"\n",
    "    seg_pred = {}\n",
    "    for frame_id, seg_id in enumerate(segment_ids):\n",
    "        if seg_id not in seg_pred:\n",
    "            seg_pred[seg_id] = []\n",
    "        seg_pred[seg_id].append(y_pred[frame_id])\n",
    "\n",
    "    ncorrect = 0\n",
    "    for seg_id in seg_pred.keys():\n",
    "        predicted = seg_pred[seg_id]\n",
    "        c = Counter(predicted)\n",
    "        predicted_label = c.most_common()[0][0] # take the majority voting\n",
    "\n",
    "        if predicted_label == segment2label[seg_id]:\n",
    "            ncorrect += 1\n",
    "\n",
    "    accuracy = ncorrect/len(segment2label)\n",
    "    print('Segment-based Accuracy using %d testing samples: %f' % (len(segment2label), accuracy))\n",
    "\n",
    "device = ('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        ### BEGIN YOUR CODE (10 points)\n",
    "        # ç‰¹å¾ç»´åº¦ã€éšå±‚ç¥žç»å…ƒã€\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=32, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.fc = Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=32*2, out_features=32), # åŒå‘LSTM\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=32, out_features=7)\n",
    "        )\n",
    "        ### END YOUR CODE\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        ### BEGIN YOUR CODE (5 points)\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr = 1e-2)\n",
    "        torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0) # T_maxè¡¨ç¤ºå‘¨æœŸçš„1/2 eta_minè¡¨ç¤ºå­¦ä¹ çŽ‡å˜åŒ–çš„æœ€å°å€¼\n",
    "        ### END YOUR CODE\n",
    "        return optimizer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:,-1,:] # æœ€åŽä¸€ä¸ªæ—¶åˆ»çš„ç»“æžœ\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class PhonemeClassifier(object):\n",
    "    def __init__(self):\n",
    "        unique_phonemes = ['CL', 'SF', 'VS', 'WF', 'ST', 'NF', \"q\"]\n",
    "        self.labels = unique_phonemes\n",
    "        self.train_epoch = 20\n",
    "\n",
    "    def label_to_ids(self, y):\n",
    "        y_ = [self.labels.index(label) for label in y]\n",
    "        return y_\n",
    "\n",
    "    def id_to_label(self, y):\n",
    "        y_ = [self.labels[i] for i in y]\n",
    "        return y_\n",
    "\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        y_train = self.label_to_ids(y_train)\n",
    "        y_train = np.asarray(y_train)\n",
    "        \n",
    "        ### BEGIN YOUR CODE (15 points)\n",
    "        X_train = torch.from_numpy(X_train).float().reshape((-1, 39, 1))\n",
    "        y_train = torch.Tensor(y_train).long()\n",
    "        \n",
    "        dataset = TensorDataset(X_train, y_train)\n",
    "        dataset = DataLoader(dataset, batch_size=4096, shuffle=True)\n",
    "        \n",
    "        self.model = Model()\n",
    "        self.model = self.model.to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimizer = self.model.get_optimizer()\n",
    "        self.model.train()\n",
    "        for epoch in range(self.train_epoch):\n",
    "            total_loss = 0\n",
    "            for data in dataset:\n",
    "                x, y = data\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = self.model(x)\n",
    "                loss = loss_fn(y_pred, y)\n",
    "                total_loss += loss\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        ### END YOUR CODE\n",
    "\n",
    "    def test(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        @arguments:\n",
    "        X_test: #frames, #features (39 for mfcc)\n",
    "        y_test: frame labels\n",
    "        \"\"\"\n",
    "        ### BEGIN YOUR CODE (5 points)\n",
    "        X_test = torch.from_numpy(X_test).float().reshape((-1, 39, 1))\n",
    "        X_test = X_test.to(device)\n",
    "        self.model.eval()\n",
    "        label_pred = self.model(X_test)\n",
    "        out_classes = torch.argmax(label_pred, axis=1)\n",
    "        ### END YOUR CODE\n",
    "        \n",
    "        out_classes = self.id_to_label(out_classes) # from id to string\n",
    "        out_classes = np.asarray(out_classes)\n",
    "        acc = sum(out_classes == y_test) * 1.0 / len(out_classes)\n",
    "        print('Frame-based Accuracy using %d testing samples: %f' % (X_test.shape[0], acc))\n",
    "\n",
    "        return out_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dd2e70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame-based Accuracy using 19424 testing samples: 0.508701\n",
      "Segment-based Accuracy using 3324 testing samples: 0.448857\n"
     ]
    }
   ],
   "source": [
    "from submission import model\n",
    "\n",
    "wav_files, label_files = read_data_folder(\"audio/part-1/train\")\n",
    "X_train, y_train, _, _  = prepare_data(wav_files, label_files)\n",
    "\n",
    "X_train, scaler_mean = normalize_mean(X_train)\n",
    "    \n",
    "wav_files, label_files = read_data_folder(\"audio/part-1/val\")\n",
    "print (len(wav_files), len(label_files))\n",
    "X_test, y_test, test_seg_ids, test_seg2labels  = prepare_data(\n",
    "        wav_files, label_files)\n",
    "X_test = apply_normalize_mean(X_test, scaler_mean)\n",
    "\n",
    "cls = model.PhonemeClassifier()\n",
    "cls.train(X_train, y_train)\n",
    "y_pred = cls.test(X_test, y_test)\n",
    "\n",
    "model.segment_based_evaluation(y_pred, test_seg_ids, test_seg2labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5a5693",
   "metadata": {},
   "source": [
    "### V. Written Report (15%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a3448f",
   "metadata": {},
   "source": [
    "#### Question 1 (10%):\n",
    "\n",
    "Describe your classification model.\n",
    "\n",
    "**Answer**\n",
    "\n",
    "In this experiment, I use BiLSTM + MLP as the final model. Since I convert the input into data with shape (batch_size, 39, 1), so the BiLSTM model is with 1 feature dimension, 39 sequence dimension, 32 hidden layer neurons. \n",
    "\n",
    "The results of the last timestamp after the BiLSTM model are inputted into the MLP model, and the MLP model have bilinear layers in shape [64 x 32], [32 x 7]. In addition, the ReLU activation function is used to improve the nonlinear expression ability, and Dropout method can prevent the model from overfitting. \n",
    "\n",
    "Regarding the optimization function, I used the Adam optimization function and the cosine annealing learning rate, where the initial learning rate is set to 1e-2, the period is 10 epoches and the learning rate minimum is set to 0.\n",
    "\n",
    "I have tried using only LSTM or just CNN, but the results are not very good. Also I have tried modifying the number of hidden layers in LSTM and MLP or changing the optimization function, but it has little effect on the result. Besizes, I want to use the LSTM + CRF model, the CRF layer can obtain the relationship between the labels and add some constraints to ensure final result is valid, but it is too complex to realize code. So I finally use the following BiLSTM + MLP model, and it acheives a pretty good result in validation dataset.\n",
    "\n",
    "\n",
    "#### Question 2 (5%)\n",
    "What is the best performance that you can get with MFCC on the validation set?\n",
    "\n",
    "**Answer**\n",
    "\n",
    "Frame-based Accuracy: 0.508701\n",
    "\n",
    "Segment-based Accuracy: 0.448857\n",
    "\n",
    "I have tried using only LSTM or just CNN, but the results are not very good. Also I have tried modifying the number of hidden layers in LSTM and MLP or changing the optimization function, but it has little effect on the result. Besizes, I want to use the LSTM + CRF model, the CRF layer can obtain the relationship between the labels and add some constraints to ensure final result is valid, but it is too complex to realize code. So I finally use the following BiLSTM + MLP model, and it acheives a pretty good result in validation dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fea45b",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa43a561",
   "metadata": {},
   "source": [
    "## Part 2: Implementing CTC Loss (45 points)\n",
    "\n",
    " We introduce the Connectionist Temporal Classification (CTC) objective, which is a popular objective used to train neural networks to do speech recognition. Critically, it does not require you to know the alignments between inputs and outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d11cb91",
   "metadata": {},
   "source": [
    "### **Summary of CTC**\n",
    "\n",
    "We highlight some of the main features of the CTC objective.\n",
    "\n",
    "- Given a sequence of inputs `x_1, x_2, .., x_T`, an ASR model will map each of these to a probability of an alphabet of C tokens: `p_1, p_2, ..., p_T`. For example, if we are decoding to three possible characters, the probabilities for timestep `t` could look like `p_t = [0.3, 0.2, 0.5]`.\n",
    "\n",
    "- We also have a sequence of symbol targets `y_1, y_2, ..., y_S` (note `S <= T`). Each `y_s` is a number from `0` to `C-1` (e.g. one of the characters).\n",
    "\n",
    "- The main strategy is to decode each `x_t` to a predicted character `y'_t`. For example, `x_1, x_2, ..., x_6 -> c c a a a t`. This mapping is called an **alignment**. Then we can collapse repetitions to get `c a t` as the predicted output sequence. This simple strategy has some problems: how do you handle silences or repeated characters?\n",
    "\n",
    "- CTC adds a special `blank` token. We'll call this `eps`. Now consider this example, `x_1, x_2, ..., x_12 -> h h e eps eps l l l eps l l o`. Now we can collapse everything in between each `eps` to get `h e eps l eps l o`. Removing blank tokens, we get the prediction `hello`.\n",
    "\n",
    "- For an output sequence, there are many \"valid\" alignments. For example, given an input sequence `x_1, ..., x_6` and an output sequence `c a t`, valid alignments include `eps c c eps a t`, `c c a a t t`, or `c a eps eps eps t`. Example of invalid alignments include `c eps c eps a t`, `c c a a t` (too short if the input sequence has 6 tokens), and `c eps eps eps t t`.\n",
    "\n",
    "- Let `A` represent all valid alignments of an output sequence to an input sequence. A simplified pseudocode for the CTC objective might look like:\n",
    "\n",
    "```\n",
    "all_log_prob = 0\n",
    "\n",
    "for each (a_1, a_2, ..., a_S) in A:\n",
    "\n",
    "    log_prob = 0\n",
    "\n",
    "    for t in 1 to T:\n",
    "        # The alignment a_s has a specific output character for input position t\n",
    "        log_prob_t = log p(a_(s,t) | x_1, ..., x_T)\n",
    "        # compute the joint probability by multiplying independent time steps\n",
    "        # Adding in log space to avoid underflow\n",
    "        log_prob += log_prob_t\n",
    "\n",
    "    all_log_prob += log_prob\n",
    "```\n",
    "That is, the CTC loss computes the probability of all possible alignments. Please note that the pseudocode above is for intuition. In practice, it is often too slow to enumerate over `A` explicitly. \n",
    "\n",
    "As an example, for an output sequence of length 50 (without any repeated characters) and an input sequence of length 100, the number of unique alignments is almost 10^40. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d5d857",
   "metadata": {},
   "source": [
    "### Task 1.1 CTC Objective (20 Points)\n",
    "Please write a function in PyTorch that given a minibatch of model predicted probabilities and a minibatch of output sequences, computes the CTC objective.\n",
    "\n",
    "**Note:** You cannot use the built-in `F.ctc_loss` in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a822465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import packages\n",
    "import nltk\n",
    "import os\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "\n",
    "FIX_SEED = 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01ca968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_loss(\n",
    "    log_probs: torch.FloatTensor, targets: torch.LongTensor,\n",
    "    input_lengths: torch.LongTensor, target_lengths: torch.LongTensor,\n",
    "    blank: int = 0) -> torch.Tensor:\n",
    "  \"\"\"\n",
    "  Connectionist Temporal Classification implementation.\n",
    "  \n",
    "  Args:\n",
    "    log_probs: The log-beliefs returned by an ASR model.\n",
    "      This is `log p(a_t | x_1, ..., x_T)`.\n",
    "      (Shape: T x batch_size x C, where T is a maximum input sequence length and\n",
    "      C is the alphabet size (including blank))\n",
    "\n",
    "    targets: Sequence of contiguous output labels (no blanks).\n",
    "      This is `y_1, ..., y_S`.\n",
    "      (Shape: batch_size x S, where S is a maximum output sequence length)\n",
    "\n",
    "    input_lengths: Lengths of each example in minibatch (<= T).\n",
    "      (Shape: batch_size)\n",
    "\n",
    "    target_lengths: Lengths of each target in minibatch (<= S).\n",
    "      (Shape: batch_size)\n",
    "\n",
    "    blank: The \"epsilon\" token that is used to represent silence.\n",
    "      (integer <= C, default 0)\n",
    "\n",
    "  Returns:\n",
    "    CTC loss averaged over minibatch.\n",
    "  \"\"\"\n",
    "  #############################\n",
    "  #### YOUR CODE GOES HERE ####\n",
    "  losses = []\n",
    "  log_probs = torch.exp(log_probs)\n",
    "  T, C = log_probs.shape[0], log_probs.shape[-1]\n",
    "  \n",
    "  for i, target in enumerate(targets):\n",
    "    L = 2 * target_lengths[i] + 1\n",
    "\n",
    "    # åŠ¨æ€è§„åˆ’ç®—æ³•\n",
    "    alphas = torch.zeros((L, T))\n",
    "    alphas[0, 0] = log_probs[0, i, blank] # åˆå§‹åŒ–ï¼Œåªæœ‰ä¸¤ä¸ªå€¼éžé›¶\n",
    "    alphas[1, 0] = log_probs[0, i, target[0]]\n",
    "    c = torch.sum(alphas[:, 0])\n",
    "    alphas[:, 0] /= c\n",
    "    loss = torch.log(c)\n",
    "\n",
    "    for t in range(1, T):\n",
    "      start = max(0, L - 2 * (T - t))\n",
    "      for s in range(start, L):\n",
    "        l = (s - 1) // 2\n",
    "        if s % 2 == 0: # sä¸ºblank\n",
    "            if s == 0:\n",
    "                alphas[s, t] = alphas[s, t - 1] * log_probs[t, i, blank]\n",
    "            else:\n",
    "                alphas[s, t] = (alphas[s, t - 1] + alphas[s - 1, t - 1]) * log_probs[t, i, blank]\n",
    "        elif s == 1 or target[l] == target[l - 1]: # læ˜¯sæ‰€å¯¹åº”çš„å­—ç¬¦,l-1æ˜¯s-2å¯¹åº”çš„å­—ç¬¦\n",
    "            alphas[s, t] = (alphas[s, t - 1] + alphas[s - 1, t - 1]) * log_probs[t, i, target[l]]\n",
    "        else:\n",
    "            alphas[s, t] = (alphas[s, t - 1] + alphas[s - 1, t - 1] + alphas[s - 2, t - 1]) * log_probs[t, i, target[l]]\n",
    "\n",
    "      c = torch.sum(alphas[:, t])\n",
    "      alphas[:, t] = alphas[:, t] / c\n",
    "      loss += torch.log(c) # æ¯ä¸ªæ—¶é—´æ­¥ç‹¬ç«‹ï¼Œå› æ­¤æ¦‚çŽ‡ç›¸ä¹˜\n",
    "    losses.append(-loss)\n",
    "  return torch.mean(torch.stack(losses))\n",
    "  #############################\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfd4be7",
   "metadata": {},
   "source": [
    "Here is a good sanity check. Test you code by checking below that `test` and `soln` are roughly equal. It's okay if your solution is much slower since the Pytorch one is coded in C. However, we will deduct points if you enumerate over all alignments as this is too slow for practical use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0a3f4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114.021225 114.021225\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "log_probs = torch.randn(50, 16, 20).log_softmax(2).detach().requires_grad_() # shape [50, 16, 20] 20ä¸ªå•è¯ \n",
    "targets = torch.randint(1, 20, (16, 30), dtype=torch.long) # shape [16, 30] 30\n",
    "input_lengths = torch.full((16,), 50, dtype=torch.long) # tensor([50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]) # è¾“å…¥åºåˆ—é•¿åº¦\n",
    "target_lengths = torch.randint(10,30,(16,), dtype=torch.long) # tensor([15, 16, 10, 21, 23, 12, 16, 22, 22, 25, 28, 22, 15, 20, 28, 22]) # è¾“å‡ºåºåˆ—é•¿åº¦\n",
    "\n",
    "est = ctc_loss(log_probs, targets, input_lengths, target_lengths, blank=0)\n",
    "soln = torch.mean(F.ctc_loss(log_probs, targets, input_lengths, target_lengths, blank=0, reduction='none'))\n",
    "\n",
    "print(est.detach().numpy(), soln.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a32665",
   "metadata": {},
   "source": [
    "### Task 1.2 Demonstrate your implementation (10 points)\n",
    "\n",
    "Print your loss function results on the log_probs and targets we provide. You can load the test minibatches by calling `get_test_minibatches()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5e3ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "def get_test_minibatches() -> list:\n",
    "  \"\"\"Get minibatches to test implementation\n",
    "  Returns:\n",
    "    lists of log_probs, targets, input_lengths, target_lengths\n",
    "  \"\"\"\n",
    "  torch.manual_seed(FIX_SEED)\n",
    "  np.random.seed(FIX_SEED)\n",
    "  random.seed(FIX_SEED)\n",
    "\n",
    "  T = np.array([])\n",
    "  C = np.array([])\n",
    "  N = np.array([])  \n",
    "  S = 40  # Target sequence length of longest target in batch (padding length) # æœ€å¤§è¾“å‡ºé•¿åº¦\n",
    "  for i in range(10):\n",
    "    T = np.append(T, random.randint(i+50, i+80)) # è¾“å…¥æœ€å¤§é•¿åº¦\n",
    "    C = np.append(C, random.randint(int(0.4* T[i]), int(0.8*T[i]))) # è¯æ±‡è¡¨\n",
    "    N = np.append(N, random.randint(int(0.7 *C[i]), int(0.9*C[i]))) # batch_size\n",
    "      \n",
    "  log_probs = []\n",
    "  input_lengths = []\n",
    "  target_lengths = [] # 10 x N[i]\n",
    "  targets = []\n",
    "  for i in range(10):\n",
    "    log_probs.append(torch.randn(int(T[i]), int(N[i]), int(C[i])).log_softmax(2).detach().requires_grad_())\n",
    "    input_lengths.append(torch.full((int(N[i]),), fill_value = int(T[i]), dtype=torch.long)) \n",
    "    target_lengths.append(torch.randint(low = 1,high = S, size = (int(N[i]),), dtype=torch.long)) # \n",
    "    targets.append(torch.randint(low = 1, high = int(C[i]), size = (int(N[i]), S), dtype=torch.long))\n",
    "\n",
    "  return log_probs, targets, input_lengths, target_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "675c853d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162.18634 162.18636\n",
      "141.91972 141.91974\n",
      "216.72314 216.72314\n",
      "167.08167 167.08167\n",
      "230.66191 230.66191\n",
      "256.2111 256.2111\n",
      "232.17311 232.17313\n",
      "149.2468 149.2468\n",
      "213.34766 213.34766\n",
      "306.7374 306.7374\n"
     ]
    }
   ],
   "source": [
    "log_probs, targets, input_lengths, target_lengths = get_test_minibatches()\n",
    "\n",
    "#############################\n",
    "#### YOUR CODE GOES HERE ####\n",
    "for i in range(len(log_probs)):\n",
    "    est = ctc_loss(log_probs[i], targets[i], input_lengths[i], target_lengths[i], blank=0)\n",
    "    soln = torch.mean(F.ctc_loss(log_probs[i], targets[i], input_lengths[i], target_lengths[i], blank=0, reduction='none'))\n",
    "    print(est.detach().numpy(), soln.detach().numpy())\n",
    "\n",
    "############################# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d9d654",
   "metadata": {},
   "source": [
    "### Task 2.1 CTC Decoding (10 Points)\n",
    "\n",
    "Given a sequence of log probabilities ` p_1, ..., p_T,` we often want to decode them to the most likely output sequence `y'_1, y'_2, ..., y'_S`. Ideally, we do this exactly using the Forward-Backward algorithm, but this could be computationally infeasible. A popular thing to do in practice is to use beam search to approximate exact inference. \n",
    "\n",
    "Below, you will write a function to decode log probabilities (from a \"CTC model\") to sequences by beam search. \n",
    "\n",
    "For context: to find the maximum likelihood decoding, taking `argmax` at each timestep is not sufficient. Even though CTC assumes conditional independence between characters, greedy decoding does not take into account that multiple output sequences can collapse to the same post-collapsed transcription.\n",
    "\n",
    "As an example, suppose the pre-collapsed sequences `a a epsilon` and `a a a` are each less likely than the sequence `b b b`. Greedy decoding would pick `b b b` as the most likely sequence. However, since `a a epsilon` and `a a a` collapse to the same string `a`, we can sum their probabilities, which could be more probable than `b b b`. These kind of edge cases make beam search a more effective method for decoding CTC, even without adding a language model.\n",
    "\n",
    "We strongly recommend you read this [blog](https://distill.pub/2017/ctc), which describes how to do beam search for CTC in detail. As a hint, unlike standard beam search, after choosing the top candidates at every stage, we have to sum the probability for candidates that collapse to the same sequence. This requires you to carefully handle blank tokens (`epsilon`) and repeated tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b03d5077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import collections\n",
    "\n",
    "def beam_search(log_probs: torch.LongTensor, beam_width: int = 5) -> list:\n",
    "  \"\"\"Beam search to find the most likely sequence.\n",
    "  \n",
    "  You can assume the inputs are not in a minibatch (just a single example).\n",
    "  You can also assume the blank token is index 0.\n",
    "\n",
    "  Args:\n",
    "    log_probs: Log probabilities as defined in CTC. (Shape: T x C)\n",
    "    beam_width: Number of candidates to keep around.\n",
    "                      \n",
    "  Returns:\n",
    "    outputs: [y'_1, y'_2, ..., y'_T], where each y'_t is between 0 and C-1.\n",
    "             This represents the most likely sequence found by beam search.\n",
    "      (shape: T) \n",
    "  \"\"\"\n",
    "  #############################\n",
    "  #### YOUR CODE GOES HERE ####\n",
    "  T, C = log_probs.shape\n",
    "  beam = [(tuple(), 0)]\n",
    "\n",
    "  for t in range(T):\n",
    "    next_beam = collections.defaultdict(lambda: 0)\n",
    "    for c in range(C):\n",
    "      p = log_probs[t, c]\n",
    "      for prefix, l_p in beam:\n",
    "        n_prefix = prefix + (c, )\n",
    "        n_p = p + l_p\n",
    "        next_beam[n_prefix] = n_p\n",
    "\n",
    "    beam = sorted(next_beam.items(), key=lambda x: x[1], reverse=True)\n",
    "    beam = beam[:beam_width]\n",
    "\n",
    "  best = beam[0]\n",
    "  return best[0]\n",
    "  #############################\n",
    "\n",
    "\n",
    "def ctc_decode(\n",
    "    log_probs: torch.LongTensor, blank: int = 0, beam_width: int = 5) -> list:\n",
    "  \"\"\"Decoding with CTC.\n",
    "\n",
    "  Use beam search to approximate the maximum likelihood decoding\n",
    "  from `log_probs`. Make sure that blank tokens are removed afterwards\n",
    "  and unnecessary repeated tokens are removed as well.\n",
    "\n",
    "  Args:\n",
    "    log_probs: log probabilities as defined in CTC. (shape: T x C)\n",
    "    blank: The \"epsilon\" token that is used to represent silence.\n",
    "      (integer <= C, default 0)\n",
    "    beam_width: The number of candidates to keep around.\n",
    "\n",
    "  Returns:\n",
    "    outputs: [y'_1, y'_2, ..., y'_S], where each y'_t is between 0 and C-1.\n",
    "      (shape: S (!= T))\n",
    "  \"\"\"\n",
    "  #############################\n",
    "  #### YOUR CODE GOES HERE ####\n",
    "  def logsum(*nums):\n",
    "    if all(n == -math.inf for n in nums):\n",
    "        return -math.inf\n",
    "    n_max = max(nums)\n",
    "    res = math.log(sum(math.exp(n - n_max) for n in nums))\n",
    "    return n_max + res\n",
    "  \n",
    "  T, C = log_probs.shape\n",
    "  beam = [(tuple(), (0.0, -math.inf))]\n",
    "\n",
    "  for t in range(T):\n",
    "    next_beam = collections.defaultdict(lambda: (-math.inf, -math.inf))\n",
    "    for c in range(C):\n",
    "      p = log_probs[t, c]\n",
    "      # p_nbä»£è¡¨å‰ç¼€ä¸ä»¥blankç»“å°¾çš„æ¦‚çŽ‡ï¼Œp_bä»£è¡¨ä»¥blankç»“å°¾çš„æ¦‚çŽ‡\n",
    "      for prefix, (p_b, p_nb) in beam:\n",
    "        if c == blank: # å¦‚æžœæ˜¯blankï¼Œå‰ç¼€ä¸æ”¹å˜ï¼Œåªæœ‰æ¦‚çŽ‡æ”¹å˜\n",
    "          n_p_b, n_p_nb = next_beam[prefix]\n",
    "          n_p_b = logsum(n_p_b, p_b + p, p_nb + p)\n",
    "          next_beam[prefix] = (n_p_b, n_p_nb)\n",
    "          continue\n",
    "        # å¦‚æžœä¸æ˜¯blankï¼Œåªæœ‰ä¸ä»¥blankç»“å°¾çš„å‰ç¼€æ¦‚çŽ‡æ”¹å˜\n",
    "        end_t = prefix[-1] if prefix else None\n",
    "        n_prefix = prefix + (c, )\n",
    "        n_p_b, n_p_nb = next_beam[n_prefix]\n",
    "        if c != end_t:\n",
    "          n_p_nb = logsum(n_p_nb, p_b + p, p_nb + p)\n",
    "        else:\n",
    "          n_p_nb = logsum(n_p_nb, p_b + p)\n",
    "        next_beam[n_prefix] = (n_p_b, n_p_nb)\n",
    "        # å¦‚æžœcåœ¨æœ«å°¾é‡å¤ï¼Œæˆ‘ä»¬ä¹Ÿè¦æ›´æ–°ä¸å˜çš„å‰ç¼€\n",
    "        if c == end_t:\n",
    "          n_p_b, n_p_nb = next_beam[prefix]\n",
    "          n_p_nb = logsum(n_p_nb, p_nb + p)\n",
    "          next_beam[prefix] = (n_p_b, n_p_nb)\n",
    "    beam = sorted(next_beam.items(), key=lambda x: logsum(*x[1]), reverse=True)\n",
    "    beam = beam[:beam_width]\n",
    "\n",
    "  best = beam[0]\n",
    "  return best[0]\n",
    "  #############################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e507c8f6",
   "metadata": {},
   "source": [
    "### Task 2.2 Demonstrate beam search decoding (3 points)\n",
    "\n",
    "Print the most likely transcript for each `log_probs` and character set we provide. Use the default beam width (=5). You can load the test data  by calling `get_log_probs()`. Please loop through  `log_probs_batch` to get `log_probs` input to test your beam search implementation. You will output 10 likely transcripts by using the test `log_probs` in `log_probs_batch`.\n",
    "\n",
    "**Note:** The most likely transcript could be gibberish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67ccc423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def get_log_probs() -> torch.LongTensor:\n",
    "  \"\"\"Get minibatches to test implementation\n",
    "  Returns:\n",
    "    lists of log_probs\n",
    "  \"\"\"\n",
    "  torch.manual_seed(FIX_SEED)\n",
    "  np.random.seed(FIX_SEED)\n",
    "  random.seed(FIX_SEED)\n",
    "\n",
    "  T = 50 # input length\n",
    "  N = 10 # Batch size\n",
    "  C = 27 # Class size\n",
    "\n",
    "  # \"CTC model\" probabilities\n",
    "  log_probs_batch = torch.randn(N, T, C).log_softmax(2).detach().requires_grad_()\n",
    "  return log_probs_batch \n",
    "\n",
    "log_probs_batch = get_log_probs() # Shape: N x T x C (10, 50, 27)\n",
    "\n",
    "\n",
    "log_probs_list = get_log_probs()\n",
    "char_set = list(string.ascii_lowercase) # lowercase alphabet\n",
    "char_set.insert(0, \"eps\") # add blank as the first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "499bf725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zcithbajqdyzioztzvwchqaqtctjzykrpgkosyjtm\n",
      "ykslbkqrhytwfvodqizhsgiqdksizqoenodvtwvrdxtqre\n",
      "rzecdjuoxbmcszemnzaqvupdvgjfxubnfuwaiokauhrsbxb\n",
      "dwnwibcsroudtquafefgvctnkzatncpyigrzkfnzb\n",
      "iudltveubgpathqgmbmajnqdfrlbuveydaipmq\n",
      "yhcnpvhwclomufngxqwgmhorfywufkhatsrstxtbqnpc\n",
      "zqhjtgngmoamfeicenkyxeuwfcejpsdgwsvbwqoukf\n",
      "vwmchnrdwdvwthgblpmyzfpqfaxvyzdbwiautkgtxkal\n",
      "khakqcosaqacerkmjbctwjmghuifymgdsecvsdnpwnzji\n",
      "pxrkpwsezuqykqkodqifkuvlcjzqrjfadrhwjrkuakfsvy\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "#### YOUR CODE GOES HERE ####\n",
    "N = log_probs_batch.shape[0]\n",
    "for i in range(N):\n",
    "\tpred_seq = ctc_decode(log_probs_batch[i, :, :], beam_width = 5)\n",
    "\tpred_seq = [char_set[_] for _ in pred_seq]\n",
    "\tpred_seq = ''.join(pred_seq)\n",
    "\tprint(pred_seq)\n",
    "\n",
    "############################# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4e6268",
   "metadata": {},
   "source": [
    "### Task 2.3 Demonstrate narrowed beam search (2 points)\n",
    "Print the most likely transcript for each `log_probs` and character set we provide. Use a narrow beam (=2) and comment on any difference you see with the narrow beam as compared to using the default beam size above. Do you find the same sequences? You can load the test data by calling `get_log_probs()`. Please loop through  `log_probs_batch` to get `log_probs` input to test your implementation. You will output 10 likely transcripts by using the test `log_probs` in `log_probs_batch`.\n",
    "\n",
    "**Note:** The most likely transcript could be gibberish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9d94486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eps', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "log_probs_list = get_log_probs()\n",
    "char_set = list(string.ascii_lowercase) # lowercase alphabet\n",
    "char_set.insert(0, \"eps\") # add blank as the first element\n",
    "print(char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b1ade33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zcithbajqdyzoztzvwchqaqtctjzykrpgkosyjtm\n",
      "ykslbkqrhutwfvodqizhsgiqdksizqoenodvtwvrdxtqre\n",
      "rzecdjuoxbmcszemnzaqvupdvgjfxubnfuwaiokauhrsbxb\n",
      "dwnwibcsroudtquafejflgvctnkzatnqcpyigrzkfnzb\n",
      "iudltveubgpathqgmbmajnqdfrlbuvejyaipmq\n",
      "yhcnpvhwclomufngxqwgmhorfywufkhatsrstxtbqnpc\n",
      "zqhjtgngmoamfeicwenkyxeuwfcejpsdgwsvbwqoukf\n",
      "vwmchnrdwdvwthgblpmyzfpqfaxvyzdbwiautkgtxkal\n",
      "nohakqcosaqackexjkmjbctwjmghuifymgdsecvsdnpwnzji\n",
      "pxrkpwsezuqykqkodqifkuvlcjzqrjfadrhwjrkuakfsvy\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "#### YOUR CODE GOES HERE ####\n",
    "N = log_probs_batch.shape[0]\n",
    "for i in range(N):\n",
    "\tpred_seq = ctc_decode(log_probs_batch[i, :, :], beam_width = 2)\n",
    "\tpred_seq = [char_set[_] for _ in pred_seq]\n",
    "\tpred_seq = ''.join(pred_seq)\n",
    "\tprint(pred_seq)\n",
    "############################# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac9142f",
   "metadata": {},
   "source": [
    "**Answer** \n",
    "\n",
    "I find many same sequences, and I think the reason is that the probility dataset we build is too small and we use the softmax operation, so the likelihood can be very extreme. Thus the narrowed beam search can also find similar answers.\n",
    "\n",
    "However, when it applied to real scenes, I think the narrowed beam search is more likely to lead to a poor performance, resulting a suboptimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b331135",
   "metadata": {},
   "source": [
    "This is the end of HW2. Great work! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:introRL] *",
   "language": "python",
   "name": "conda-env-introRL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "188a1d607666d26341b4aeacf8ee052faf3945c44a9ff0d1a699f32494ac6a63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
