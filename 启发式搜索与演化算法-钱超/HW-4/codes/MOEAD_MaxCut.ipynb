{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def generate_regular_graph():\n",
    "    # 这里简单以正则图为例, 鼓励同学们尝试在其他类型的图(具体可查看如下的nx文档)上测试算法性能\n",
    "    # nx文档 https://networkx.org/documentation/stable/reference/generators.html\n",
    "    graph = nx.random_graphs.random_regular_graph(d=99, n=200, seed=2023)\n",
    "    return graph, len(graph.nodes), len(graph.edges)\n",
    "\n",
    "def generate_erdos_renyi_graph():\n",
    "    graph = nx.random_graphs.erdos_renyi_graph(n=180, p=0.52, seed=2023)\n",
    "    return graph, len(graph.nodes), len(graph.edges)\n",
    "\n",
    "data_path = 'regular'\n",
    "\n",
    "if data_path == 'regular':\n",
    "    graph, n_nodes, n_edges = generate_regular_graph()\n",
    "elif data_path == 'ER':\n",
    "    graph, n_nodes, n_edges = generate_erdos_renyi_graph()\n",
    "    \n",
    "print(n_nodes, n_edges)\n",
    "def get_fitness(graph, x, threshold=0):\n",
    "    # 获得Cuts值需要将图分为两部分, 这里默认以0为阈值把解分成两块.\n",
    "    g1 = np.where(x == 0)[0]\n",
    "    g2 = np.where(x == 1)[0]\n",
    "    return -nx.cut_size(graph, g1, g2) / n_edges\n",
    "\n",
    "import numpy as np\n",
    "k = 8\n",
    "n = n_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = round(n*k*k*2*np.exp(1))\n",
    "mse = []\n",
    "N = 100\n",
    "neigh_num = 5\n",
    "\n",
    "# 生成权重向量\n",
    "def gen_mean_vector(N, m):\n",
    "    def _distribution_number(sum, m):\n",
    "        if m == 1:\n",
    "            return [[sum]]\n",
    "        vectors = []\n",
    "        for i in range(1, sum - (m - 1) + 1):\n",
    "            right_vec = _distribution_number(sum - i, m - 1)\n",
    "            vectors.extend([i] + item for item in right_vec)\n",
    "        return vectors\n",
    "    \n",
    "    vectors = _distribution_number(N + m, m)\n",
    "    vectors = (np.array(vectors) - 1) / N\n",
    "    return vectors, len(vectors)\n",
    "\n",
    "# 初始化距离\n",
    "def init_distances(vectors):\n",
    "    distances = np.zeros((popSize, popSize))\n",
    "    for i, j in itertools.product(range(popSize), range(popSize)):\n",
    "        distance = ((vectors[i] - vectors[j]) ** 2).sum()\n",
    "        distances[i][j] = distance\n",
    "    return distances\n",
    "\n",
    "# 初始化种群\n",
    "def initialize(popSize):\n",
    "    population, neighbors = [], []\n",
    "    for _ in range(popSize):\n",
    "        while True:\n",
    "            ind = np.random.choice((0, 1), p = (1 - k / n, k / n), size = n)\n",
    "            if ind.sum() <= k:\n",
    "                break\n",
    "\n",
    "        population.append(ind)\n",
    "    for _ in range(popSize):\n",
    "        sort_arg = np.argsort(distances[_])\n",
    "        neighbors.append([sort_arg[i] for i in range(neigh_num)])\n",
    "    return population, neighbors\n",
    "\n",
    "vectors, popSize = gen_mean_vector(N, 2)\n",
    "distances = init_distances(vectors)\n",
    "population, neighbors = initialize(popSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import lstsq\n",
    "\n",
    "def mutation(ind):\n",
    "    individual = ind.copy()\n",
    "    p = k / n\n",
    "    m = np.random.choice((0,1), p=(1-p, p), size=n)\n",
    "    flip = 1 - individual\n",
    "    individual = np.where(m, flip, individual)\n",
    "    return np.array(individual)\n",
    "\n",
    "def crossover(individual_a, individual_b, n):\n",
    "    l = len(individual_a)\n",
    "    offspring_a = np.zeros((n))\n",
    "    offspring_b = np.zeros((n))\n",
    "\n",
    "    m = np.arange(l) < np.random.randint(l + 1)\n",
    "    offspring_a = np.where(m, individual_a, individual_b)\n",
    "    offspring_b = np.where(~m, individual_a, individual_b)\n",
    "\n",
    "    return offspring_a, offspring_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function1_values, function2_values = [0 for _ in range(popSize)], [0 for _ in range(popSize)]\n",
    "for i in range(popSize):\n",
    "    loss = get_fitness(graph, population[i])\n",
    "    function2_values[i] = population[i].sum() if (0 < population[i].sum() <= 2 * k) else 999999999999\n",
    "    function1_values[i] = loss if (0 <= population[i].sum() <= 2 * k) else 999999999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "EP = []  # 前沿\n",
    "EP_fx = []  # ep对应的目标值\n",
    "mse = []\n",
    "\n",
    "def funcs(ind):\n",
    "    loss = get_fitness(graph, ind)\n",
    "    f2 = ind.sum() if (0 < ind.sum() <= 2 * k) else 999999999999\n",
    "    f1 = loss if (0 <= ind.sum() <= 2 * k) else 999999999999\n",
    "    return f1, f2\n",
    "\n",
    "for _ in range(T):\n",
    "    for i in range(len(population)):\n",
    "        neighbor = neighbors[i]\n",
    "        idx = np.random.randint(0, neigh_num, size=2)\n",
    "        p1, p2 = neighbor[idx[0]], neighbor[idx[1]] # 索引\n",
    "        d1, d2 = crossover(population[p1], population[p2], n)\n",
    "        d1, d2 = mutation(d1), mutation(d2)\n",
    "        \n",
    "        idx2 = np.random.randint(0, neigh_num, size=2)\n",
    "        t1, t2 = neighbor[idx2[0]], neighbor[idx2[1]] # 索引\n",
    "        \n",
    "        d1_f1, d1_f2 = funcs(d1)\n",
    "        d1_comp = vectors[t1][0] * (d1_f1 - function1_values[t1]) + \\\n",
    "            vectors[t1][1] * (d1_f2 - function2_values[t1]) / (2 * k) # d1和t1比较\n",
    "        if d1_comp < 0:\n",
    "            population[t1] = d1\n",
    "            function1_values[t1], function2_values[t1] = d1_f1, d1_f2\n",
    "            \n",
    "            # 将新解与EP每一个进行比较，删除被新解支配的，如果新解没有被旧解支配，则保留\n",
    "            accept_new = True\n",
    "            for j in range(len(EP) - 1, -1, -1):  # 从后往前遍历\n",
    "                old_fx = EP_fx[j]\n",
    "                if (old_fx[0] < d1_f1 and old_fx[1] <= d1_f2) or (old_fx[0] <= d1_f1 and old_fx[1] < d1_f2):\n",
    "                    accept_new = False\n",
    "                    break\n",
    "                elif (old_fx[0] > d1_f1 and old_fx[1] >= d1_f2) or (old_fx[0] >= d1_f1 and old_fx[1] > d1_f2)\\\n",
    "                    or (old_fx[0] == d1_f1 and old_fx[1] == d1_f2) / (2 * k):\n",
    "                    del EP[j], EP_fx[j]\n",
    "                    continue\n",
    "\n",
    "            if accept_new:\n",
    "                EP.append(d1)\n",
    "                EP_fx.append([d1_f1, d1_f2])\n",
    "\n",
    "        d2_f1, d2_f2 = funcs(d2)\n",
    "        d2_comp = vectors[t2][0] * (d2_f1 - function1_values[t2]) + \\\n",
    "            vectors[t2][1] * (d2_f2 - function2_values[t2]) # d2和t2比较\n",
    "        if d2_comp < 0:\n",
    "            population[t2] = d2\n",
    "            function1_values[t2], function2_values[t2] = d2_f1, d2_f2\n",
    "            \n",
    "            # 将新解与EP每一个进行比较，删除被新解支配的，如果新解没有被旧解支配，则保留\n",
    "            accept_new = True\n",
    "            for j in range(len(EP) - 1, -1, -1):  # 从后往前遍历\n",
    "                old_fx = EP_fx[j]\n",
    "                if (old_fx[0] < d2_f1 and old_fx[1] <= d2_f2) or (old_fx[0] <= d2_f1 and old_fx[1] < d2_f2):\n",
    "                    accept_new = False\n",
    "                    break\n",
    "                elif (old_fx[0] > d2_f1 and old_fx[1] >= d2_f2) or (old_fx[0] >= d2_f1 and old_fx[1] > d2_f2)\\\n",
    "                    or (old_fx[0] == d2_f1 and old_fx[1] == d2_f2):\n",
    "                    del EP[j], EP_fx[j]\n",
    "                    continue\n",
    "\n",
    "            if accept_new:\n",
    "                EP.append(d2)\n",
    "                EP_fx.append([d2_f1, d2_f2])\n",
    "            \n",
    "    if _ and _ % (T // 10000) == 0:\n",
    "        res = np.array(EP_fx).T\n",
    "        mse_loss = min(res[0][res[1] <= 8])\n",
    "        mse.append(mse_loss)\n",
    "        print(mse_loss, len(EP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(res[0], res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = res\n",
    "tt = [_ * T // 100 for _ in range(100)]\n",
    "mse = np.array(mse)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['science'])\n",
    "with plt.style.context(['science']):\n",
    "    plt.figure()\n",
    "    plt.plot(tt, mse)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('mse')\n",
    "    plt.title(f'moea: {data_path}')\n",
    "    plt.savefig(f'MOEA_{data_path}.pdf')\n",
    "    plt.close()\n",
    "    \n",
    "with plt.style.context(['science']):\n",
    "    plt.scatter(ep[1], ep[0])\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('mse')\n",
    "    plt.title(f'Pareto front- moea: {data_path}')\n",
    "    plt.savefig(f'MOEA_{data_path}_pareto.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'MOEA_{data_path}_t.npy', tt)\n",
    "np.save(f'MOEA_{data_path}_mse.npy', mse)\n",
    "np.save(f'MOEA_{data_path}_pareto.npy', ep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "introRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "188a1d607666d26341b4aeacf8ee052faf3945c44a9ff0d1a699f32494ac6a63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
